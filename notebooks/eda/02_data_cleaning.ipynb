{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f43dc9d3-31ef-4a1c-a605-94537215fe9d",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "In this notebook, the raw NYC taxi dataset is being cleaned by:\n",
    "- Removing invalid and corrupt records\n",
    "- Handling missing values\n",
    "- Filtering implausible trips\n",
    "- Standardizing schema\n",
    "- Validating key business constraints\n",
    "\n",
    "The goal is to produce a modeling-ready dataset that aligns with the projectâ€™s data dictionary and analytical assumptions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfb4f5a4-f710-4670-b2cd-1b84ab005165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded raw snapshot: (22519712, 19)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "RAW_SNAPSHOT_PATH = \"../../data/processed/raw_combined_2019_q1.parquet\"\n",
    "CLEAN_PATH = \"../../data/processed/nyc_clean_2019_q1.parquet\"\n",
    "\n",
    "df = pd.read_parquet(RAW_SNAPSHOT_PATH)\n",
    "print(\"Loaded raw snapshot:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22604938-fdb5-4c8d-8073-2d73e39fb4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create copy\n",
    "df_clean = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfbe6bd-1c2e-4c40-8119-6127c8cbf7ce",
   "metadata": {},
   "source": [
    "A working copy of the raw dataset is created to ensure reproducibility and preserve the original data for auditing and debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b0bb599-4391-4982-b79e-03e67d862ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data based on passenger count violations\n",
    "df_clean = df_clean[df_clean[\"passenger_count\"].between(1, 6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0836c56-6dc6-44c3-89bc-6eef0ed7f3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data based on trip distance violations\n",
    "df_clean = df_clean[df_clean[\"trip_distance\"] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb58941d-e5c1-4359-9459-b8c9c0cd51a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data based on fare and total amount violations\n",
    "df_clean = df_clean[\n",
    "    (df_clean[\"fare_amount\"] > 0) &\n",
    "    (df_clean[\"total_amount\"] > 0)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e11f8563-1b6e-465b-9536-e4608cc43441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate trip duration in minutes\n",
    "df_clean[\"trip_duration_min\"] = (\n",
    "    (df_clean[\"tpep_dropoff_datetime\"] - df_clean[\"tpep_pickup_datetime\"])\n",
    "    .dt.total_seconds() / 60\n",
    ")\n",
    "\n",
    "# Filter data based on trip duration violations\n",
    "df_clean = df_clean[\n",
    "    (df_clean[\"trip_duration_min\"] > 0) &\n",
    "    (df_clean[\"trip_duration_min\"] < 240)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec5a462-4354-43eb-96cd-3b069b1f239a",
   "metadata": {},
   "source": [
    "### Validity Filtering\n",
    "\n",
    "We remove trips that violate basic physical and business constraints:\n",
    "\n",
    "- Passenger count outside [1, 6]\n",
    "- Non-positive trip distance\n",
    "- Non-positive fare or total amount\n",
    "- Negative or extremely long trip durations (> 4 hours)\n",
    "\n",
    "These records are treated as corrupt and excluded from analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e533d899-c530-47c6-801e-ee33990b9b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enforce time window\n",
    "start_date = \"2019-01-01\"\n",
    "end_date   = \"2019-03-31 23:59:59\"\n",
    "\n",
    "df_clean = df_clean[\n",
    "    (df_clean[\"tpep_pickup_datetime\"] >= start_date) &\n",
    "    (df_clean[\"tpep_pickup_datetime\"] <= end_date)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5b50af-f5c3-4a7e-abc2-17254af8fa6b",
   "metadata": {},
   "source": [
    "### Time Window Enforcement\n",
    "\n",
    "Some trips fall outside the intended January-March 2019 window.\n",
    "\n",
    "These records are excluded to enforce a strict analytical slice and prevent time leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5cbac16-7109-4e75-bad3-2f748d530ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing congestion subcharge values\n",
    "df_clean[\"congestion_surcharge\"] = df_clean[\"congestion_surcharge\"].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5874b3e5-31ab-4ab2-8c47-ff67706f8f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing tip amount values\n",
    "df_clean[\"tip_amount\"] = df_clean[\"tip_amount\"].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e866462-1e8a-4d99-a420-56f03d78d4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing store and forward flag\n",
    "df_clean[\"store_and_fwd_flag\"] = df_clean[\"store_and_fwd_flag\"].fillna(\"N\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf6b00e-d26c-4ca9-80dd-2b94403e85ad",
   "metadata": {},
   "source": [
    "### Missing Value Handling\n",
    "\n",
    "- `congestion_surcharge` NAs are filled with 0s, as this was introduced later in 2019 and only applies to specific zones and conditions.\n",
    "- `tip_amount` NAs are filled with 0s, as no-tip rides are valid.\n",
    "- `store_and_fwd_flag` is filled with \"N\" if missing.\n",
    "\n",
    "No rows are dropped solely due to missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff2f7780-b522-4ace-a83a-64618a4c81ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier filtering\n",
    "df_clean = df_clean[\n",
    "    (df_clean[\"trip_distance\"] < 100) &\n",
    "    (df_clean[\"fare_amount\"] < 500)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1816421-7766-4830-b4ea-62d1828655a0",
   "metadata": {},
   "source": [
    "### Outlier Filtering\n",
    "\n",
    "We apply outlier filters to remove extreme values likely caused by recording errors:\n",
    "\n",
    "- Trip distance more than 100 miles\n",
    "- Fare amount more than $500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "774307e4-1a06-4285-8d35-54ccf5f43396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema Standardization\n",
    "df_clean.columns = (\n",
    "    df_clean.columns\n",
    "    .str.lower()\n",
    "    .str.replace(\" \", \"_\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9bec5083-ec9c-495d-8792-9a5c5a92a49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before cleaning: 22519712\n",
      "Rows after cleaning: 21903044\n",
      "Dropped rows: 616668\n",
      "NA values:\n",
      "vendorid                 0\n",
      "tpep_pickup_datetime     0\n",
      "tpep_dropoff_datetime    0\n",
      "passenger_count          0\n",
      "trip_distance            0\n",
      "ratecodeid               0\n",
      "store_and_fwd_flag       0\n",
      "pulocationid             0\n",
      "dolocationid             0\n",
      "payment_type             0\n",
      "fare_amount              0\n",
      "extra                    0\n",
      "mta_tax                  0\n",
      "tip_amount               0\n",
      "tolls_amount             0\n",
      "improvement_surcharge    0\n",
      "total_amount             0\n",
      "congestion_surcharge     0\n",
      "source_file              0\n",
      "trip_duration_min        0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendorid</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>ratecodeid</th>\n",
       "      <th>pulocationid</th>\n",
       "      <th>dolocationid</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>trip_duration_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.190304e+07</td>\n",
       "      <td>21903044</td>\n",
       "      <td>21903044</td>\n",
       "      <td>2.190304e+07</td>\n",
       "      <td>2.190304e+07</td>\n",
       "      <td>2.190304e+07</td>\n",
       "      <td>2.190304e+07</td>\n",
       "      <td>2.190304e+07</td>\n",
       "      <td>2.190304e+07</td>\n",
       "      <td>2.190304e+07</td>\n",
       "      <td>2.190304e+07</td>\n",
       "      <td>2.190304e+07</td>\n",
       "      <td>2.190304e+07</td>\n",
       "      <td>2.190304e+07</td>\n",
       "      <td>2.190304e+07</td>\n",
       "      <td>2.190304e+07</td>\n",
       "      <td>2.190304e+07</td>\n",
       "      <td>2.190304e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.646588e+00</td>\n",
       "      <td>2019-02-15 07:39:05.272758016</td>\n",
       "      <td>2019-02-15 07:52:42.906417920</td>\n",
       "      <td>1.598944e+00</td>\n",
       "      <td>2.912673e+00</td>\n",
       "      <td>1.051840e+00</td>\n",
       "      <td>1.635959e+02</td>\n",
       "      <td>1.618016e+02</td>\n",
       "      <td>1.274207e+00</td>\n",
       "      <td>1.258252e+01</td>\n",
       "      <td>8.793517e-01</td>\n",
       "      <td>4.980721e-01</td>\n",
       "      <td>2.062933e+00</td>\n",
       "      <td>3.393932e-01</td>\n",
       "      <td>2.999816e-01</td>\n",
       "      <td>1.760019e+01</td>\n",
       "      <td>1.480001e+00</td>\n",
       "      <td>1.362723e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>2019-01-01 00:01:33</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>-6.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.100000e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.666667e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2019-01-24 10:26:44</td>\n",
       "      <td>2019-01-24 10:43:24</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.600000e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.140000e+02</td>\n",
       "      <td>1.120000e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.500000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.000000e-01</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.433333e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2019-02-14 21:10:35</td>\n",
       "      <td>2019-02-14 21:24:42.500000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.600000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.620000e+02</td>\n",
       "      <td>1.620000e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>1.700000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.000000e-01</td>\n",
       "      <td>1.355000e+01</td>\n",
       "      <td>2.500000e+00</td>\n",
       "      <td>1.068333e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2019-03-09 12:52:24</td>\n",
       "      <td>2019-03-09 13:05:52</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2.940000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.330000e+02</td>\n",
       "      <td>2.340000e+02</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.400000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>2.750000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.000000e-01</td>\n",
       "      <td>1.896000e+01</td>\n",
       "      <td>2.500000e+00</td>\n",
       "      <td>1.741667e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>2019-03-31 23:59:57</td>\n",
       "      <td>2019-04-01 00:46:12</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>9.920000e+01</td>\n",
       "      <td>9.900000e+01</td>\n",
       "      <td>2.650000e+02</td>\n",
       "      <td>2.650000e+02</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>4.680000e+02</td>\n",
       "      <td>1.850000e+01</td>\n",
       "      <td>6.080000e+01</td>\n",
       "      <td>7.872500e+02</td>\n",
       "      <td>3.288000e+03</td>\n",
       "      <td>6.000000e-01</td>\n",
       "      <td>3.345300e+03</td>\n",
       "      <td>2.750000e+00</td>\n",
       "      <td>2.399333e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.243316e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.220717e+00</td>\n",
       "      <td>3.788318e+00</td>\n",
       "      <td>4.922610e-01</td>\n",
       "      <td>6.603537e+01</td>\n",
       "      <td>7.019011e+01</td>\n",
       "      <td>4.600162e-01</td>\n",
       "      <td>1.106150e+01</td>\n",
       "      <td>1.136347e+00</td>\n",
       "      <td>3.929350e-02</td>\n",
       "      <td>2.560341e+00</td>\n",
       "      <td>1.795537e+00</td>\n",
       "      <td>2.351680e-03</td>\n",
       "      <td>1.380448e+01</td>\n",
       "      <td>1.228652e+00</td>\n",
       "      <td>1.069030e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           vendorid           tpep_pickup_datetime  \\\n",
       "count  2.190304e+07                       21903044   \n",
       "mean   1.646588e+00  2019-02-15 07:39:05.272758016   \n",
       "min    1.000000e+00            2019-01-01 00:00:00   \n",
       "25%    1.000000e+00            2019-01-24 10:26:44   \n",
       "50%    2.000000e+00            2019-02-14 21:10:35   \n",
       "75%    2.000000e+00            2019-03-09 12:52:24   \n",
       "max    4.000000e+00            2019-03-31 23:59:57   \n",
       "std    5.243316e-01                            NaN   \n",
       "\n",
       "               tpep_dropoff_datetime  passenger_count  trip_distance  \\\n",
       "count                       21903044     2.190304e+07   2.190304e+07   \n",
       "mean   2019-02-15 07:52:42.906417920     1.598944e+00   2.912673e+00   \n",
       "min              2019-01-01 00:01:33     1.000000e+00   1.000000e-02   \n",
       "25%              2019-01-24 10:43:24     1.000000e+00   9.600000e-01   \n",
       "50%       2019-02-14 21:24:42.500000     1.000000e+00   1.600000e+00   \n",
       "75%              2019-03-09 13:05:52     2.000000e+00   2.940000e+00   \n",
       "max              2019-04-01 00:46:12     6.000000e+00   9.920000e+01   \n",
       "std                              NaN     1.220717e+00   3.788318e+00   \n",
       "\n",
       "         ratecodeid  pulocationid  dolocationid  payment_type   fare_amount  \\\n",
       "count  2.190304e+07  2.190304e+07  2.190304e+07  2.190304e+07  2.190304e+07   \n",
       "mean   1.051840e+00  1.635959e+02  1.618016e+02  1.274207e+00  1.258252e+01   \n",
       "min    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e-02   \n",
       "25%    1.000000e+00  1.140000e+02  1.120000e+02  1.000000e+00  6.500000e+00   \n",
       "50%    1.000000e+00  1.620000e+02  1.620000e+02  1.000000e+00  9.000000e+00   \n",
       "75%    1.000000e+00  2.330000e+02  2.340000e+02  2.000000e+00  1.400000e+01   \n",
       "max    9.900000e+01  2.650000e+02  2.650000e+02  4.000000e+00  4.680000e+02   \n",
       "std    4.922610e-01  6.603537e+01  7.019011e+01  4.600162e-01  1.106150e+01   \n",
       "\n",
       "              extra       mta_tax    tip_amount  tolls_amount  \\\n",
       "count  2.190304e+07  2.190304e+07  2.190304e+07  2.190304e+07   \n",
       "mean   8.793517e-01  4.980721e-01  2.062933e+00  3.393932e-01   \n",
       "min   -6.000000e+01  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    0.000000e+00  5.000000e-01  0.000000e+00  0.000000e+00   \n",
       "50%    5.000000e-01  5.000000e-01  1.700000e+00  0.000000e+00   \n",
       "75%    1.000000e+00  5.000000e-01  2.750000e+00  0.000000e+00   \n",
       "max    1.850000e+01  6.080000e+01  7.872500e+02  3.288000e+03   \n",
       "std    1.136347e+00  3.929350e-02  2.560341e+00  1.795537e+00   \n",
       "\n",
       "       improvement_surcharge  total_amount  congestion_surcharge  \\\n",
       "count           2.190304e+07  2.190304e+07          2.190304e+07   \n",
       "mean            2.999816e-01  1.760019e+01          1.480001e+00   \n",
       "min             0.000000e+00  3.100000e-01          0.000000e+00   \n",
       "25%             3.000000e-01  1.000000e+01          0.000000e+00   \n",
       "50%             3.000000e-01  1.355000e+01          2.500000e+00   \n",
       "75%             3.000000e-01  1.896000e+01          2.500000e+00   \n",
       "max             6.000000e-01  3.345300e+03          2.750000e+00   \n",
       "std             2.351680e-03  1.380448e+01          1.228652e+00   \n",
       "\n",
       "       trip_duration_min  \n",
       "count       2.190304e+07  \n",
       "mean        1.362723e+01  \n",
       "min         1.666667e-02  \n",
       "25%         6.433333e+00  \n",
       "50%         1.068333e+01  \n",
       "75%         1.741667e+01  \n",
       "max         2.399333e+02  \n",
       "std         1.069030e+01  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Post-Cleaning validation\n",
    "print(\"Rows before cleaning:\", len(df))\n",
    "print(\"Rows after cleaning:\", len(df_clean))\n",
    "print(\"Dropped rows:\", len(df) - len(df_clean))\n",
    "\n",
    "print(\"NA values:\")\n",
    "print(df_clean.isna().sum())\n",
    "df_clean.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e08f8e-c580-49fe-9d2b-98997fc2d5ab",
   "metadata": {},
   "source": [
    "### Post-Cleaning Validation\n",
    "\n",
    "After cleaning:\n",
    "\n",
    "- Verify that no critical columns contain missing values.\n",
    "- Ensure that all trips satisfy business and physical constraints.\n",
    "- Log the number of rows removed to quantify data quality impact.\n",
    "\n",
    "This dataset is now suitable for feature engineering and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d5ece6b-68fe-493f-93b0-5f08f0a117a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save clean snapshot\n",
    "df_clean.to_parquet(CLEAN_PATH, index=False, engine=\"fastparquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c6455b-3028-418e-a5e3-45efe6a0aed9",
   "metadata": {},
   "source": [
    "## Cleaning Summary\n",
    "\n",
    "- Raw rows: 22,519,712  \n",
    "- Clean rows: 21,903,044  \n",
    "- Dropped rows: 616,668 (~2.7%)\n",
    "\n",
    "The cleaned dataset contains no missing values and satisfies all validity rules, making it suitable for feature engineering and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb748f9-a4e5-485e-be4c-5d3db961e2dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
